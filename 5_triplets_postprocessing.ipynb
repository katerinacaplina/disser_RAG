{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку локальные модели порой склонны к галлюцинациям, мы дополнительно проведем постобработку сгенерированных триплетов. Сначала мы используем эвристики и удаляем триплеты, если они не полные по структуре, например, отсутствует один из элементов sub, rel или obj, если один из элементов пустой или содержит значение unknow.\n",
    "Следующим шагом мы при помощи LLM делаем дополнительную проверку на факты в триплете и в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import LlamaCpp\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры скрипта\n",
    "\n",
    "# DOMAIN = 'movie'\n",
    "# DOMAIN = 'computer'\n",
    "DOMAIN = 'nature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secrets.yaml', 'r') as f:\n",
    "    secrets = yaml.safe_load(f)\n",
    "\n",
    "openai_key = secrets['openai_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('artifacts', DOMAIN, 'triples_ft.jsonl'), 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначаем список стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_to_remove = [\"unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем кастомный промпт, при помощи которого модель будет анализировать предоставленные триплеты и текст и возвращать значение True или False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are provided triplet in format [subject, relation, object]. Also you provided a sentence. If information in triplet fully connected with sentence, you should answer \"True\". Otherwise, you should answer \"False\". If triplet containts information, that does not reflect in sentence, return \"False\".\n",
    "Your output must be in format \"True\" or \"False\". Do not add any additional information.\n",
    "Check that your output must be only \"True\" or \"False\"\n",
    "triplet: {triplet}\n",
    "sentence: {sentence}\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве модели-инспектора можно выбрать OpenAI или использовать локальную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4-1106-preview\", \n",
    "             openai_api_key = openai_key,\n",
    "             max_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"../models/openchat-3.5-0106.Q8_0.gguf\"\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=model_path,\n",
    "#     temperature=0,\n",
    "#     max_tokens=4000,\n",
    "#     n_gpu_layers= 200,\n",
    "#     n_batch = 512,\n",
    "#     n_threads=8,\n",
    "#     top_p=1,\n",
    "#     n_ctx=2048\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект chain из langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\"\n",
    "triplet = [\"Bleach: Hell Verse\", \"directed by\", \"Noriyuki Abe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' True\\n\\nHuman'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = check_chain.invoke({\"triplet\": triplet, \"sentence\": sentence})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "дадим модели заведомо ложный пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bleach: Hell Verse (Japanese: BLEACH , Hepburn: BurÄ«chi Jigoku-Hen) is a 2010 Japanese animated film directed by Noriyuki Abe.\"\n",
    "triplet = [\"Bleach: Hell Verse\", \"directed by\", \"Noriyuki Isida\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' False\\n\\nHuman'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = check_chain.invoke({\"triplet\": triplet, \"sentence\": sentence})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оформим весь процесс постобработки в функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplets_postprocessing(data, check_chain):\n",
    "    filtered_data = []\n",
    "    for i_line in tqdm(data):\n",
    "        temp_dict = dict()\n",
    "        json_data = json.loads(i_line)\n",
    "        temp_dict[\"model\"] = json_data.get('model', f'{json_data.get(\"model1\")+json_data.get(\"model2\")}')\n",
    "        temp_dict['sent'] = json_data['sent']\n",
    "        temp_dict['triples'] = []\n",
    "        if len(json_data['triples']) > 0:\n",
    "            for i_triple in json_data['triples']:\n",
    "                if (\"obj\" in i_triple) and (\"rel\" in i_triple) and (\"sub\" in i_triple):\n",
    "                    if (len(i_triple['obj']) > 0) and (\"obj\" in i_triple) and (\"rel\" in i_triple) and (i_triple['obj'] not in stop_words_to_remove):\n",
    "                        triplet_str = [i_triple['sub'], i_triple['rel'], i_triple['obj']]\n",
    "                        check = check_chain.invoke({\"triplet\": triplet_str, \"sentence\": json_data['sent']})\n",
    "                        if \"true\" in check.lower():\n",
    "                            temp_dict['triples'].append(i_triple)\n",
    "        filtered_data.append(temp_dict)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:18<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "filtered_data = triplets_postprocessing(data, check_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем файл на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('artifacts', DOMAIN, 'triples_ft_pp.jsonl'), 'w', encoding='utf-8') as f:\n",
    "    for entry in filtered_data:\n",
    "        json_record = json.dumps(entry, ensure_ascii=False)\n",
    "        f.write(json_record + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
